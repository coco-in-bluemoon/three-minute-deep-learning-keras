{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "chapter4_2_cnn_cifar10_cl.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coco-in-bluemoon/three-minute-deep-learning-keras/blob/main/notebook/chapter4_2_cnn_cifar10_cl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "J3iYAwiWzqy3"
      },
      "source": [
        "**⚠️ Original Code in error️**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-VS-JJVzqy3"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZJ4HeCnrzqy3"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, Dense, Dropout, Flatten, MaxPooling2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4To1jcXFzqy3"
      },
      "source": [
        "class CNN(Model):\n",
        "    def __init__(model, nb_classes, in_shape=None):\n",
        "        model.nb_classes = nb_classes\n",
        "        model.in_shape = in_shape\n",
        "        model.build_model()\n",
        "        super().__init__(model.x, model.y)\n",
        "        model.compile()\n",
        "\n",
        "    def build_model(model):\n",
        "        nb_classes = model.nb_classes\n",
        "        in_shape = model.in_shape\n",
        "\n",
        "        x = Input(in_shape)\n",
        "\n",
        "        h = Conv2D(32, kernel_size=(3, 3), activation='relu',\n",
        "                   input_shape=in_shape)(x)\n",
        "        h = Conv2D(64, (3, 3), activation='relu')(h)\n",
        "        h = MaxPooling2D(pool_size=(2, 2))(h)\n",
        "        h = Dropout(0.25)(h)\n",
        "        h = Flatten()(h)\n",
        "        z_cl = h\n",
        "\n",
        "        h = Dense(128, activation='relu')(h)\n",
        "        h = Dropout(0.5)(h)\n",
        "        z_fl = h\n",
        "\n",
        "        y = Dense(nb_classes, activation='softmax', name='preds')(h)\n",
        "\n",
        "        model.cl_part = Model(x, z_cl)\n",
        "        model.fl_part = Model(x, z_fl)\n",
        "\n",
        "        model.x, model.y = x, y\n",
        "\n",
        "    def compile(model):\n",
        "        Model.compile(model, loss='categorical_crossentropy',\n",
        "                      optimizer='adadelta', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cSUMtItOzqy3"
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KOQNt7qDzqy3"
      },
      "source": [
        "class Dataset:\n",
        "    def __init__(self, X, y, nb_classes, scaling=True, test_size=0.2, random_state=0):\n",
        "        self.X = X\n",
        "        self.add_channels()\n",
        "\n",
        "        X = self.X\n",
        "        X_train, X_test, y_train, y_test =\\\n",
        "            train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "        print(X_train.shape, y_train.shape)\n",
        "\n",
        "        X_train = X_train.astype('float32')\n",
        "        X_test = X_test.astype('float32')\n",
        "\n",
        "        if scaling:\n",
        "            scaler = MinMaxScaler()\n",
        "            n = X_train.shape[0]\n",
        "            X_train = scaler.fit_transform(X_train.reshape(n, -1)).reshape(X_train.shape)\n",
        "            n = X_test.shape[0]\n",
        "            X_test = scaler.transform(X_test.reshape(n, -1)).reshape(X_test.shape)\n",
        "\n",
        "            self.scaler = scaler\n",
        "\n",
        "        print('X_train shape: ', X_train.shape)\n",
        "        print(X_train.shape[0], ' train samples')\n",
        "        print(X_test.shape[0], ' test samples')\n",
        "\n",
        "        Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "        Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "\n",
        "        self.X_train, self.X_test = X_train, X_test\n",
        "        self.y_train, self.y_test = y_train, y_test\n",
        "        self.Y_train, self.Y_test = Y_train, Y_test\n",
        "\n",
        "    def add_channels(self):\n",
        "        X = self.X\n",
        "\n",
        "        if len(X.shape) == 3:\n",
        "            N, img_rows, img_cols = X.shape\n",
        "\n",
        "            if K.image_dim_ordering() == 'th':\n",
        "                X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
        "                input_shape = (1, img_rows, img_cols)\n",
        "            else:\n",
        "                X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
        "                input_shape = (img_rows, img_cols, 1)\n",
        "        else:\n",
        "            input_shape = X.shape[1:]\n",
        "\n",
        "        self.X = X\n",
        "        self.input_shape = input_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "iCiCXHb-zqy3"
      },
      "source": [
        "from datetime import datetime\n",
        "import os\n",
        "import uuid\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "y_cRul4nzqy3"
      },
      "source": [
        "class Machine:\n",
        "    def __init__(self, X, y, nb_classes=2, fig=True):\n",
        "        self.nb_classes = nb_classes\n",
        "        self.set_data(X, y)\n",
        "        self.set_model()\n",
        "        self.fig = fig\n",
        "\n",
        "    def set_data(self, X, y):\n",
        "        nb_classes = self.nb_classes\n",
        "        self.data = Dataset(X, y, nb_classes)\n",
        "        print('data.input_shape', self.data.input_shape)\n",
        "\n",
        "    def set_model(self):\n",
        "        nb_classes = self.nb_classes\n",
        "        data = self.data\n",
        "        self.model = CNN(nb_classes, data.input_shape)\n",
        "\n",
        "    def fit(self, epochs=10, batch_size=128, verbose=1):\n",
        "        data = self.data\n",
        "        model = self.model\n",
        "\n",
        "        history = model.fit(\n",
        "            data.X_train, data.Y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            verbose=verbose,\n",
        "            validation_data=(data.X_test, data.Y_test)\n",
        "        )\n",
        "        return history\n",
        "\n",
        "    def run(self, epochs=100, batch_size=128, verbose=1):\n",
        "        data = self.data\n",
        "        model = self.model\n",
        "        fig = self.fig\n",
        "\n",
        "        history = self.fit(epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "        score = model.evaluate(data.X_test, data.Y_test, verbose=0)\n",
        "\n",
        "        print('Confusion Matrix')\n",
        "        Y_test_pred = model.predict(data.X_test, verbose=0)\n",
        "        y_test_pred = np.argmax(Y_test_pred, axis=1)\n",
        "        print(metrics.confusion_matrix(data.y_test, y_test_pred))\n",
        "\n",
        "        print('Test Score:', score[0])\n",
        "        print('Test Accuracy:', score[1])\n",
        "\n",
        "        suffix = self.unique_filename('datetime')\n",
        "        foldname = 'output_' + suffix\n",
        "        os.makedirs(foldname)\n",
        "        self.save_history_history('history_history.npz', history.history, foldname)\n",
        "        model.save_weights(os.path.join(foldname, 'dl_model.h5'))\n",
        "        print('Output results are saved in', foldname)\n",
        "\n",
        "        if fig:\n",
        "            plt.figure(figsize=(12, 4))\n",
        "            plt.subplot(1, 2, 1)\n",
        "            self.plot_acc(history)\n",
        "            plt.subplot(1, 2, 2)\n",
        "            self.plot_loss(history)\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "        self.history = history\n",
        "\n",
        "        return foldname\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def unique_filename(type='uuid'):\n",
        "        if type == 'datetime':\n",
        "            filename = datetime.now().strftime('%y%m%d_%H%M%S')\n",
        "        elif type == 'uuid':\n",
        "            filename = str(uuid.uuid4())\n",
        "\n",
        "        return filename\n",
        "\n",
        "    @staticmethod\n",
        "    def save_history_history(fname, history_history, fold=''):\n",
        "        np.save(os.path.join(fold, fname), history_history)\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_acc(history):\n",
        "        plt.plot(history.history['acc'])\n",
        "        plt.plot(history.history['val_acc'])\n",
        "        plt.title('Model Accuracy')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Test'], loc=0)\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_acc(history):\n",
        "        plt.plot(history.history['loss'])\n",
        "        plt.plot(history.history['val_loss'])\n",
        "        plt.title('Model Loss')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Test'], loc=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Afam2ueUzqy3"
      },
      "source": [
        "from keras import datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zjG_tqJZzqy3"
      },
      "source": [
        "class Cifar10Machine(Machine):\n",
        "    def __init__(self):\n",
        "        (X, y), (x_test, y_test) = datasets.cifar10.load_data()\n",
        "        super(Cifar10Machine, self).__init__(X, y, nb_classes=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ST80V2OBzqy3"
      },
      "source": [
        "def main():\n",
        "    m = Cifar10Machine()\n",
        "    m.run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "UJw2wkjRzqy4",
        "outputId": "0d3a7d1a-768f-4adc-9f34-a1b82e83935e"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000, 32, 32, 3) (40000, 1)\n",
            "X_train shape:  (40000, 32, 32, 3)\n",
            "40000  train samples\n",
            "10000  test samples\n",
            "data.input_shape (32, 32, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "It looks like you are subclassing `Model` and you forgot to call `super(YourClass, self).__init__()`. Always start with this line.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-3fe6d6c817b2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCifar10Machine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-86b78034c6cf>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcifar10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCifar10Machine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-b232798f63fb>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, X, y, nb_classes, fig)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-b232798f63fb>\u001b[0m in \u001b[0;36mset_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mnb_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-b6cbcbc40868>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(model, nb_classes, in_shape)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-b6cbcbc40868>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'preds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcl_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_cl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_fl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Workspaces/Study/Books/three-minute-deep-learning-keras/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    336\u001b[0m             RuntimeError('It looks like you are subclassing `Model` and you '\n\u001b[1;32m    337\u001b[0m                          \u001b[0;34m'forgot to call `super(YourClass, self).__init__()`.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                          ' Always start with this line.'), None)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Workspaces/Study/Books/three-minute-deep-learning-keras/venv/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: It looks like you are subclassing `Model` and you forgot to call `super(YourClass, self).__init__()`. Always start with this line."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "o_WuR_oLzqy4"
      },
      "source": [
        "**☕️ My Refactored Code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Ts1MXyV-zqy4"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qInPyb7Fzqy4"
      },
      "source": [
        "from keras import layers, models"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6IkjAZuXzqy4"
      },
      "source": [
        "class CNNModel(models.Model):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        super(CNNModel, self).__init__()\n",
        "\n",
        "        self.conv1 = layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape)\n",
        "        self.conv2 = layers.Conv2D(32, kernel_size=(3, 3), activation='relu')\n",
        "        self.pool = layers.MaxPooling2D(pool_size=(2, 2))\n",
        "        self.dropout1 = layers.Dropout(0.25)\n",
        "        self.flatten = layers.Flatten()\n",
        "        self.dense1 = layers.Dense(128, activation='relu')\n",
        "        self.dropout2 = layers.Dropout(0.5)\n",
        "        self.dense2 = layers.Dense(num_classes, activation='softmax')\n",
        "\n",
        "\n",
        "    def call(self, x):\n",
        "        net = self.conv1(x)\n",
        "        net = self.conv2(net)\n",
        "        net = self.pool(net)\n",
        "        net = self.dropout1(net)\n",
        "        net = self.flatten(net)\n",
        "        net = self.dense1(net)\n",
        "        net = self.dropout2(net)\n",
        "        y = self.dense2(net)\n",
        "\n",
        "        return y\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super(CNNModel, self).get_config()\n",
        "        return base_config"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "BQKXn2CCzqy4"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KUKfBv8Fzqy4"
      },
      "source": [
        "class Dataset:\n",
        "    def __init__(self, x, y, num_classes, scaling=True, test_size=0.2, random_state=2020):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "        x_train, x_test, y_train, y_test = train_test_split(\n",
        "            x, y, test_size=test_size, random_state=random_state\n",
        "        )\n",
        "\n",
        "        x_train = x_train.astype('float32')\n",
        "        x_test = x_test.astype('float32')\n",
        "\n",
        "        x_train_scaled = None\n",
        "        x_test_scaled = None\n",
        "        if scaling:\n",
        "            min_max_scale = MinMaxScaler()\n",
        "\n",
        "            num_train_sample = x_train.shape[0]\n",
        "            image_width = x_train.shape[1]\n",
        "            image_height = x_train.shape[2]\n",
        "            image_channel = x_train.shape[3]\n",
        "\n",
        "            x_train_scaled = min_max_scale\\\n",
        "                .fit_transform(x_train.reshape(num_train_sample, -1))\\\n",
        "                .reshape((num_train_sample, image_width, image_height, image_channel))\n",
        "\n",
        "            num_test_sample = x_test.shape[0]\n",
        "\n",
        "            x_test_scaled = min_max_scale\\\n",
        "                .fit_transform(x_test.reshape(num_test_sample, -1))\\\n",
        "                .reshape((num_test_sample, image_width, image_height, image_channel))\n",
        "\n",
        "            self.input_shape = (image_width, image_height, image_channel)\n",
        "            self.scale = min_max_scale\n",
        "\n",
        "        y_train_encoded = np_utils.to_categorical(y_train, num_classes)\n",
        "        y_test_encoded = np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "        self.x_train = x_train_scaled if scaling else x_train\n",
        "        self.x_test = x_test_scaled if scaling else x_test\n",
        "        self.y_train = y_train_encoded\n",
        "        self.y_test = y_test_encoded"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hz4B2wzMzqy4"
      },
      "source": [
        "class Classifier:\n",
        "    def __init__(self, x, y, num_classes, fig=True):\n",
        "        self.num_classes = num_classes\n",
        "        self.fig = fig\n",
        "\n",
        "        self.data = Dataset(x, y, num_classes=num_classes)\n",
        "        self.model = CNNModel(input_shape=self.data.input_shape, num_classes=num_classes)\n",
        "        self.model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['acc'])\n",
        "\n",
        "    def fit(self):\n",
        "        x_train = self.data.x_train\n",
        "        y_train = self.data.y_train\n",
        "        x_test = self.data.x_test\n",
        "        y_test = self.data.y_test\n",
        "\n",
        "        self.model.fit(x_train, y_train, epochs=20, batch_size=128, validation_data=(x_test, y_test), verbose=1)\n",
        "\n",
        "    def score(self):\n",
        "        x_test = self.data.x_test\n",
        "        y_test = self.data.y_test\n",
        "        score = self.model.evaluate(x_test, y_test)\n",
        "        print(score)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "bYG2vtS4zqy4"
      },
      "source": [
        "from keras import datasets"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Mcgjrx5ezqy4",
        "outputId": "a553c284-0795-4f6b-c509-d95357d737dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
        "classifier = Classifier(x_train, y_train, 10)\n",
        "classifier.fit()\n",
        "classifier.score()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.6955 - acc: 0.3814 - val_loss: 1.4198 - val_acc: 0.4890\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.3876 - acc: 0.5044 - val_loss: 1.2302 - val_acc: 0.5756\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.2473 - acc: 0.5560 - val_loss: 1.0958 - val_acc: 0.6138\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.1679 - acc: 0.5870 - val_loss: 1.0509 - val_acc: 0.6334\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.1005 - acc: 0.6108 - val_loss: 0.9931 - val_acc: 0.6510\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.0538 - acc: 0.6264 - val_loss: 0.9824 - val_acc: 0.6540\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.0143 - acc: 0.6382 - val_loss: 0.9617 - val_acc: 0.6667\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.9762 - acc: 0.6510 - val_loss: 0.9383 - val_acc: 0.6677\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.9467 - acc: 0.6599 - val_loss: 0.9376 - val_acc: 0.6739\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.9196 - acc: 0.6704 - val_loss: 0.9236 - val_acc: 0.6793\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.8952 - acc: 0.6798 - val_loss: 0.9493 - val_acc: 0.6712\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.8614 - acc: 0.6907 - val_loss: 0.9015 - val_acc: 0.6850\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.8493 - acc: 0.6956 - val_loss: 0.9149 - val_acc: 0.6827\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.8209 - acc: 0.7067 - val_loss: 0.9177 - val_acc: 0.6849\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.8010 - acc: 0.7107 - val_loss: 0.8936 - val_acc: 0.6948\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.7876 - acc: 0.7162 - val_loss: 0.9207 - val_acc: 0.6829\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.7722 - acc: 0.7190 - val_loss: 0.8990 - val_acc: 0.6957\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.7519 - acc: 0.7286 - val_loss: 0.8924 - val_acc: 0.6964\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.7358 - acc: 0.7333 - val_loss: 0.9013 - val_acc: 0.6980\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.7203 - acc: 0.7384 - val_loss: 0.9181 - val_acc: 0.6879\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.9181 - acc: 0.6879\n",
            "[0.9181039929389954, 0.6879000067710876]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "yvY4Rg2rzqy5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}